1. Super- vised machine learning models have shown great success in this area but they require a large number of labeled documents to reach adequate accuracy. This is particularly true when the number of target categories is in the tens or the hundreds.
2. We find that the proposed model of tokenization provides an improvement in the performance of text classifi- cation with a simple LSTM classifier. 
3. This re- sults in improved performance for sentiment anal- ysis tasks on Japanese and English datasets and Chinese datasets with a larger cache. We find that the proposed model of tokenization provides an improvement in the performance of text classifi- cation with a simple LSTM classifier.
4. Twitter数据集F1 67.75 https://www.kaggle.com/c/ twitter-sentiment-analysis2
5. In recent years, lots of works have been done to solve text classification problems, but just a few of them have explored the explainability of their systems (Camburu et al., 2018; Ouyang et al., 2018). Ribeiro et al. (2016) try to identify an inter- pretable model over the interpretable representa- tion that is locally faithful to the classifier. 
6. To achieve these goals, in this paper, we pro- pose a novel generative explanation framework for text classification, where our model is capable of not only providing the classification predictions but also generating fine-grained information as ex- planations for decisions. The novel idea behind our hybrid generative-discriminative method is to explicitly capture the fine-grained information in- ferred from raw texts, utilizing the information to help interpret the predicted classification results and improve the overall performance.
7. In this paper, we confirm that these models are useful for text classification when the number of labeled instances is small, but demonstrate that fine-tuning to in-domain data is also of critical importance. 
8. Inherent problems in data emerge in a trained model in several ways. Model explanations can show that the model is not inline with human judg- ment or domain expertise. A canonical example is model unfairness, which stems from biases in the training data. 
9. Our ap- proach relies on re-using model parameters trained at upper levels in the taxonomy and fine-tuning them for classifying categories at lower levels.
10. One critical issue is that the number of local classifiers depends on the size of the label hierarchy, making local approaches in- feasible to scale.
11. Most of the current effective methods for text classification task are based on large-scale la- beled data and a great number of parame- ters, but when the supervised training data are few and difficult to be collected, these mod- els are not available.
12. The dominant text classification models in deep learning require a considerable amount of labeled data to learn a large num- ber of parameters. However, such methods may have difficulty in learning the semantic space in the case that only few data are available. 
13. However, it is not always realistic to assume that example labels are clean. Humans make mistakes and, depending on the complexity of the task, there may be disagreement even among expert la- belers.
14. 1 http://nlp.stanford.edu/sentiment/  2 http://cogcomp.cs.illinois.edu/Data/QA/QC/ 3.http://www.di.unipi.it/ ̃gulli/AG_ corpus_of_news_articles.html
15. In the future, we plan to in- vestigate broader applications like summarizaion, translation, question answering, etc.
16. As one of the most fundamental problems in ma- chine learning, automatic classification has been widely studied in several domains. However, many approaches, proven to be effective in tradi- tional classification tasks, cannot catch up with a dynamic and open environment where new classes can emerge after the learning stage (Romera- Paredes and Torr, 2015). For example, the number of topics on social media is growing rapidly, and the classification models are required to recognise the text of the new topics using only general in- formation (e.g., descriptions of the topics) since labelled training instances are unfeasible to ob- tain for each new topic (Lee et al., 2011). This scenario holds in many real-world domains such as object recognition and medical diagnosis (Xian et al., 2017; World Health Organization, 1996).