### Towards Unsupervised Text Classification Leveraging Experts and Word Embeddings

In this work, we explore an unsupervised approach to classify documents into categories simply described by a label. The proposed method is inspired by the way a human proceeds in this situation: It draws on textual similarity between the most relevant words in each document and a dic- tionary of keywords for each category reflect- ing its semantics and lexical field. The nov- elty of our method hinges on the enrichment of the category labels through a combination of human expertise and language models, both generic and domain specific. Our experiments on 5 standard corpora show that the proposed method increases F1-score over relying solely on human expertise and can also be on par with simple supervised approaches. It thus provides a practical alternative to situations where low- cost text categorization is needed, as we illus- trate with our application to operational risk incidents classification.

In this paper, we present a method for unsuper- vised text classification based on computing the similarity between the documents to be classi- fied and a rich description of the categories label. The category label enrichment starts with human- expert provided keywords but is then expanded through the use of word embeddings. We also investigated whether a consolidation step that re- moves non discriminant words from the label dic- tionaries could have an effect on performance.

We have not explored whether recent advances in word embeddings from instance ELMO (Peters et al., 2018) and BERT (Devlin et al., 2018) could add further benefits. This is certainly an avenue that we seek to explore. However, for our applica- tion domain, we expect that it may not lead to in- creased performance as words are used to a large extent with the same sense across the corpus.

相似度计算，无监督学习，文本分类

### Stochastic Tokenization with a Language Model for Neural Text Classification

Sentences are usually seg- mented with words or subwords by a morpho- logical analyzer or byte pair encoding and then encoded with word (or subword) representa- tions for neural networks. However, segmenta- tion is potentially ambiguous, and it is unclear whether the segmented tokens achieve the best performance for the target task. In this pa- per, we propose a method to simultaneously learn tokenization and text classification to ad- dress these problems. Our model incorporates a language model for unsupervised tokeniza- tion into a text classifier and then trains both models simultaneously. To make the model robust against infrequent tokens, we sampled segmentation for each sentence stochastically during training, which resulted in improved performance of text classification. We con- ducted experiments on sentiment analysis as a text classification task and show that our method achieves better performance than pre- vious methods.

Twitter数据集F1 67.75 https://www.kaggle.com/c/ twitter-sentiment-analysis2

### Towards Explainable NLP: A Generative Explanation Framework for Text Classification
Building explainable systems is a critical prob- lem in the field of Natural Language Process- ing (NLP), since most machine learning mod- els provide no explanations for the predictions. Existing approaches for explainable machine learning systems tend to focus on interpret- ing the outputs or the connections between in- puts and outputs. However, the fine-grained information (e.g. textual explanations for the labels) is often ignored, and the systems do not explicitly generate the human-readable ex- planations. To solve this problem, we pro- pose a novel generative explanation frame- work that learns to make classification deci- sions and generate fine-grained explanations at the same time. More specifically, we intro- duce the explainable factor and the minimum risk training approach that learn to generate more reasonable explanations. We construct two new datasets that contain summaries, rat- ing scores, and fine-grained reasons. We con- duct experiments on both datasets, compar- ing with several strong neural network base- line systems. Experimental results show that our method surpasses all baselines on both datasets, and is able to generate concise expla- nations at the same time.

Since our proposed framework is model- agnostic, we can combine it with other natural processing tasks, e.g. summarization, extraction, which we leave to our future work.
可解释的机器学习模型

### Variational Pretraining for Semi-supervised Text Classification
We introduce VAMPIRE,1 a lightweight pre- training framework for effective text classi- fication when data and computing resources are limited. We pretrain a unigram docu- ment model as a variational autoencoder on in-domain, unlabeled data and use its inter- nal states as features in a downstream classi- fier. Empirically, we show the relative strength of VAMPIRE against computationally expen- sive contextual embeddings and other popular semi-supervised baselines under low resource settings. We also find that fine-tuning to in- domain data is crucial to achieving decent per- formance from contextual embeddings when working with limited supervision. We accom- pany this paper with code to pretrain and use VAMPIRE embeddings in downstream tasks.
轻量级的文本分类框架

### Incorporating Priors with Feature Attribution on Text Classification
Feature attribution methods, proposed re- cently, help users interpret the predictions of complex models. Our approach integrates fea- ture attributions into the objective function to allow machine learning practitioners to incor- porate priors in model building. To demon- strate the effectiveness our technique, we ap- ply it to two tasks: (1) mitigating unintended bias in text classifiers by neutralizing identity terms; (2) improving classifier performance in a scarce data setting by forcing the model to focus on toxic terms. Our approach adds an L2 distance loss between feature attributions and task-specific prior values to the objective. Our experiments show that i) a classifier trained with our technique reduces undesired model biases without a tradeoff on the original task; ii) incorporating priors helps model perfor- mance in scarce data settings.

Hence, most machine learning progress made in those areas is hindered by a lack of model explain- ability – causing practitioners to resort to simpler, potentially low-performance models.

### Hierarchical Transfer Learning for Multi-label Text Classification

Multi-Label Hierarchical Text Classification (MLHTC) is the task of categorizing docu- ments into one or more topics organized in an hierarchical taxonomy. MLHTC can be for- mulated by combining multiple binary classifi- cation problems with an independent classifier for each category. We propose a novel trans- fer learning based strategy, HTrans, where bi- nary classifiers at lower levels in the hier- archy are initialized using parameters of the parent classifier and fine-tuned on the child category classification task. In HTrans, we use a Gated Recurrent Unit (GRU)-based deep learning architecture coupled with attention. Compared to binary classifiers trained from scratch, our HTrans approach results in signifi- cant improvements of 1% on micro-F1 and 3% on macro-F1 on the RCV1 dataset. Our exper- iments also show that binary classifiers trained from scratch are significantly better than single multi-label models.

### Large-Scale Multi-Label Text Classification on EU Legislation
We consider Large-Scale Multi-Label Text Classification (LMTC) in the legal domain. We release a new dataset of 57k legislative documents from EUR-LEX, annotated with ∼4.3k EUROVOC labels, which is suitable for LMTC, few- and zero-shot learning. Exper- imenting with several neural classifiers, we show that BIGRUs with label-wise attention perform better than other current state of the art methods. Domain-specific WORD2VEC and context-sensitive ELMO embeddings fur- ther improve performance. We also find that considering only particular zones of the docu- ments is sufficient. This allows us to bypass BERT’s maximum text length limit and fine- tune BERT, obtaining the best results in all but zero-shot learning cases.


### NeuralClassifier: An Open-source Neural Hierarchical Multi-label Text Classification Toolkit
In this paper, we introduce NeuralClassifier, a toolkit for neural hierarchical multi-label text classification. NeuralClassifier is designed for quick implementation of neural models for hierarchical multi-label classification task, which is more challenging and common in real-world scenarios. A salient feature is that NeuralClassifier currently provides a variety of text encoders, such as FastText, TextCNN, TextRNN, RCNN, VDCNN, DPCNN, DRNN, AttentiveConvNet and Transformer encoder, etc. It also supports other text classification scenarios, including binary-class and multi- class classification. Built on PyTorch1 , the core operations are calculated in batch, mak- ing the toolkit efficient with the acceleration of GPU. Experiments show that models built in our toolkit achieve comparable performance with reported results in the literature

### Hierarchical Text Classification with Reinforced Label Assignment
While existing hierarchical text classification (HTC) methods attempt to capture label hier- archies for model training, they either make local decisions regarding each label or com- pletely ignore the hierarchy information dur- ing inference. To solve the mismatch between training and inference as well as modeling la- bel dependencies in a more principled way, we formulate HTC as a Markov decision pro- cess and propose to learn a Label Assignment Policy via deep reinforcement learning to de- termine where to place an object and when to stop the assignment process. The proposed method, HiLAP, explores the hierarchy dur- ing both training and inference time in a con- sistent manner and makes inter-dependent de- cisions. As a general framework, HiLAP can incorporate different neural encoders as base models for end-to-end training. Experiments on five public datasets and four base models show that HiLAP yields an average improve- ment of 33.4% in Macro-F1 over flat classifiers and outperforms state-of-the-art HTC methods by a large margin.
We proposed an end-to-end reinforcement learn- ing approach to hierarchical text classification (HTC) where objects are labeled by placing them at the proper positions in the label hierarchy. The proposed framework makes consistent and inter-dependent predictions, in which any neural- based representation learning model can be used as a base model and a label assignment policy is learned to determine where to place the objects and when to stop the assignment process. Exper- iments on five public datasets and four base mod- els showed that our approach outperforms state- of-the-art HTC methods significantly. 

### Investigating Capsule Network and Semantic Feature on Hyperplanes for Text Classification
As an essential component of natural language processing, text classification relies on deep learning in recent years. Various neural net- works are designed for text classification on the basis of word embedding. However, pol- ysemy is a fundamental feature of the natu- ral language, which brings challenges to text classification. One polysemic word contains more than one sense, while the word embed- ding procedure conflates different senses of a polysemic word into a single vector. Extract- ing the distinct representation for the specific sense could thus lead to fine-grained models with strong generalization ability. It has been demonstrated that multiple senses of a word actually reside in linear superposition within the word embedding so that specific senses can be extracted from the original word embed- ding. Therefore, we propose to use capsule networks to construct the vectorized represen- tation of semantics and utilize hyperplanes to decompose each capsule to acquire the spe- cific senses. A novel dynamic routing mech- anism named ‘routing-on-hyperplane’ will se- lect the proper sense for the downstream clas- sification task. Our model is evaluated on 6 different datasets, and the experimental re- sults show that our model is capable of ex- tracting more discriminative semantic features and yields a significant performance gain com- pared to other baseline methods.


### Label-Specific Document Representation for Multi-Label Text Classification
Multi-label text classification (MLTC) aims to tag most relevant labels for the given document. In this paper, we propose a Label-Specific Attention Network (LSAN) to learn the new document representation. LSAN takes advantage of label semantic information to determine the semantic connection between labels and document for constructing label-specific document representation. Meanwhile, the self-attention mechanism is adopted to identify the label-specific document representation from document content information. In order to seamlessly integrate the above two parts, an adaptive fusion strategy is designed, which can effectively output the comprehensive document representation to build multilabel text classifier. Extensive experimental results on four benchmark datasets demonstrate that LSAN consistently outperforms the stateof-the-art methods, especially on the prediction of low-frequency labels.

A new label-specific attention network, in this pa- per, is proposed for multi-label text classification. It makes use of document content and label text to learn the label-specific document representation with the aid of self-attention and label-attention mechanisms. An adaptive fusion is designed to ef- fectively integrate these two attention mechanisms to improve the final prediction performance. Ex- tensive experiments on four benchmark dataset- s prove the superiority of LSAN by comparing with the state-of-the-art methods, especially on the dataset with large subset of low-frequency labels.

### Hierarchical Attention Prototypical Networks for Few-Shot Text Classification
Most of the current effective methods for text classification task are based on large-scale la- beled data and a great number of parame- ters, but when the supervised training data are few and difficult to be collected, these mod- els are not available. In this paper, we pro- pose a hierarchical attention prototypical net- works (HAPN) for few-shot text classifica- tion. We design the feature level, word level, and instance level multi cross attention for our model to enhance the expressive ability of se- mantic space. We verify the effectiveness of our model on two standard benchmark few- shot text classification datasets - FewRel and CSID, and achieve the state-of-the-art perfor- mance. The visualization of hierarchical atten- tion layers illustrates that our model can cap- ture more important features, words, and in- stances separately. In addition, our attention mechanism increases support set augmentabil- ity and accelerates convergence speed in the training stage.

### An Effective Label Noise Model for DNN Text Classification
Because large, human-annotated datasets suf- fer from labeling errors, it is crucial to be able to train deep neural networks in the pres- ence of label noise. While training image classification models with label noise have re- ceived much attention, training text classifica- tion models have not. In this paper, we pro- pose an approach to training deep networks that is robust to label noise. This approach in- troduces a non-linear processing layer (noise model) that models the statistics of the la- bel noise into a convolutional neural network (CNN) architecture. The noise model and the CNN weights are learned jointly from noisy training data, which prevents the model from overfitting to erroneous labels. Through ex- tensive experiments on several text classifica- tion datasets, we show that this approach en- ables the CNN to learn better sentence repre- sentations and is robust even to extreme label noise. We find that proper initialization and regularization of this noise model is critical. Further, by contrast to results focusing on large batch sizes for mitigating label noise for image classification, we find that altering the batch size does not have much effect on classifica- tion performance.

给出了一些数据集可以参考SST-2, TREC, AGNEWS, DBPedia


### How Large a Vocabulary Does Text Classification Need? A Variational Approach to Vocabulary Selection

With the rapid development in deep learn- ing, deep neural networks have been widely adopted in many real-life natural language ap- plications. Under deep neural networks, a pre- defined vocabulary is required to vectorize text inputs. The canonical approach to select pre- defined vocabulary is based on the word fre- quency, where a threshold is selected to cut off the long tail distribution. However, we observed that such a simple approach could easily lead to under-sized vocabulary or over- sized vocabulary issues. Therefore, we are interested in understanding how the end-task classification accuracy is related to the vocab- ulary size and what is the minimum required vocabulary size to achieve a specific perfor- mance. In this paper, we provide a more sophisticated variational vocabulary dropout (VVD) based on variational dropout to per- form vocabulary selection, which can intelli- gently select the subset of the vocabulary to achieve the required performance. To eval- uate different algorithms on the newly pro- posed vocabulary selection problem, we pro- pose two new metrics: Area Under Accuracy- Vocab Curve and Vocab Size under X% Ac- curacy Drop. Through extensive experiments on various NLP classification tasks, our varia- tional framework is shown to significantly out- perform the frequency-based and other selec- tion baselines on these metrics.

In this paper, we propose a vocabulary selection algorithm which can find sparsity in the vocabu- lary and dynamically decrease its size to contain only the useful words. Through our experiments, we have empirically demonstrated that the com- monly adopted frequency-based vocabulary selec- tion is already a very strong mechanism, further applying our proposed VVD can further improve the compression ratio. However, due to the time and memory complexity issues, our algorithm and evaluation are more suitable for classification- based application. 

### Integrating Semantic Knowledge to Tackle Zero-shot Text Classification

Insufficient or even unavailable training data of emerging classes is a big challenge of many classification tasks, including text classification. Recognising text documents of classes that have never been seen in the learning stage, so-called zero-shot text classification, is there- fore difficult and only limited previous works tackled this problem. In this paper, we pro- pose a two-phase framework together with data augmentation and feature augmentation to solve this problem. Four kinds of semantic knowledge (word embeddings, class descrip- tions, class hierarchy, and a general knowl- edge graph) are incorporated into the pro- posed framework to deal with instances of un- seen classes effectively. Experimental results show that each and the combination of the two phases achieve the best overall accuracy com- pared with baselines and recent approaches in classifying real-world texts under the zero-shot scenario.


### Adaptive Convolution for Text Classification

In this paper, we present an adaptive convolution for text classification to give stronger flexibility to convolutional neural networks (CNNs). Unlike traditional convolutions that use the same set of filters regardless of different inputs, the adaptive convolution employs adaptively generated convolutional filters that are conditioned on inputs. We achieve this by attaching filter-generating networks, which are carefully designed to generate input-specific filters, to convolution blocks in existing CNNs. We show the efficacy of our approach in existing CNNs based on our performance evaluation. Our evaluation indicates that adaptive convolutions improve all the baselines, without any exception, as much as up to 2.6 percentage point in seven benchmark text classification datasets.

In this paper, we have introduced the adaptive convolution to endow flexibility to convolution operations. Further, we have proposed the hashing technique which can drastically reduce the number of parameters for adaptive convolutions. We have validated our approach based on the performance evaluation with seven datasets, and investigated the effectiveness of adaptive convolutions through analysis. We believe that our methodology is applicable to other NLP tasks with text pairs, such as textual entailment, question answering. We plan to apply the proposed approach to those tasks in the future.

